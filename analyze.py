import os
import pandas as pd
import glob
from openpyxl import load_workbook
from datetime import datetime
import plotly.express as px
import logging
from plotly.subplots import make_subplots
import plotly.graph_objects as go
import numpy as np
import time
import functools

# === –ù–ê–°–¢–†–û–ô–ö–ê –õ–û–ì–ò–†–û–í–ê–ù–ò–Ø ===
os.makedirs("–ª–æ–≥–∏", exist_ok=True)
logging.basicConfig(
    filename='–ª–æ–≥–∏/–∞–Ω–∞–ª–∏–∑_—Å–∫–ª–∞–¥–∞.log',
    level=logging.INFO,
    format='%(asctime)s ‚Äî %(levelname)s ‚Äî %(message)s'
)

def timing_decorator(func):
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        end = time.time()
        duration = end - start
        msg = f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ '{func.__name__}': {duration:.3f} —Å–µ–∫—É–Ω–¥"
        print(msg)
        logging.info(msg)
        return result
    return wrapper

@timing_decorator
def parse_date_from_cell(cell_value, file_path):
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω–æ –ø–∞—Ä—Å–∏—Ç –¥–∞—Ç—É –∏–∑ –∑–Ω–∞—á–µ–Ω–∏—è —è—á–µ–π–∫–∏.
    –ï—Å–ª–∏ –¥–∞—Ç–∞ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞, –±–µ—Ä—ë—Ç –¥–∞—Ç—É —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–∞.
    –õ–æ–≥–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç.
    """
    if cell_value is None:
        date = datetime.fromtimestamp(os.path.getctime(file_path))
        logging.warning(f'–î–∞—Ç–∞ –≤ —Ñ–∞–π–ª–µ {file_path} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –ø–æ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –¥–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–∞: {date}')
        return date

    date_str = str(cell_value).strip()
    date = pd.to_datetime(date_str, errors='coerce', dayfirst=True)
    if pd.isna(date):
        date = datetime.fromtimestamp(os.path.getctime(file_path))
        logging.warning(f'–î–∞—Ç–∞ "{date_str}" –≤ —Ñ–∞–π–ª–µ {file_path} –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞, –ø–æ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –¥–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–∞: {date}')
    else:
        logging.info(f'–î–∞—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞ {file_path}: "{date_str}" —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞ –∫–∞–∫ {date}')
    return date

@timing_decorator
def read_excel_file(file_path, sklad_name):
    extension = os.path.splitext(file_path)[1].lower()
    data = []

    try:
        if extension == '.xls':
            df_raw = pd.read_excel(file_path, header=None, engine='xlrd')
            date_cell = df_raw.iloc[1, 0]
            date = parse_date_from_cell(date_cell, file_path)

            for idx in range(4, len(df_raw)):
                row = df_raw.iloc[idx]
                if pd.isna(row[5]):
                    continue
                data.append({
                    '–î–∞—Ç–∞': date,
                    '–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞': row[1],
                    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': row[2] or 0,
                    '–¶–µ–Ω–∞': row[3] or 0,
                    '–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å': row[4],
                    '–ê—Ä—Ç–∏–∫—É–ª': str(row[5]).strip(),
                    '–°–∫–ª–∞–¥': sklad_name
                })

        elif extension == '.xlsx':
            wb = load_workbook(filename=file_path, data_only=True)
            ws = wb.active
            date_cell = ws['A2'].value
            date = parse_date_from_cell(date_cell, file_path)

            for i in range(5, ws.max_row + 1):
                article = ws[f'F{i}'].value
                if article is None:
                    continue
                data.append({
                    '–î–∞—Ç–∞': date,
                    '–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞': ws[f'B{i}'].value,
                    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': ws[f'C{i}'].value or 0,
                    '–¶–µ–Ω–∞': ws[f'D{i}'].value or 0,
                    '–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å': ws[f'E{i}'].value,
                    '–ê—Ä—Ç–∏–∫—É–ª': str(article).strip(),
                    '–°–∫–ª–∞–¥': sklad_name
                })

        logging.info(f'–£—Å–ø–µ—à–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–Ω —Ñ–∞–π–ª: {file_path}')
        return pd.DataFrame(data)

    except Exception as e:
        logging.error(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}')
        return None
@timing_decorator
def process_folder(folder_path, sklad_name):
    files = sorted(glob.glob(os.path.join(folder_path, '*.xls*')))
    dfs = []
    for file in files:
        df = read_excel_file(file, sklad_name)
        if df is not None and not df.empty:
            dfs.append(df)
    if not dfs:
        logging.warning(f'–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ –ø–∞–ø–∫–µ: {folder_path}')
        return None
    return pd.concat(dfs, ignore_index=True)
@timing_decorator
def generate_daily_sales_file(df_all: pd.DataFrame, output_path: str = '–∏—Ç–æ–≥_–¥–Ω–µ–≤–Ω—ã–µ_–ø—Ä–æ–¥–∞–∂–∏.csv'):
    try:
        if '–î–∞—Ç–∞' not in df_all.columns:
            logging.error("–ö–æ–ª–æ–Ω–∫–∞ '–î–∞—Ç–∞' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö ‚Äî –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª –µ–∂–µ–¥–Ω–µ–≤–Ω—ã—Ö –ø—Ä–æ–¥–∞–∂.")
            return

        if '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ' not in df_all.columns:
            logging.error("–ö–æ–ª–æ–Ω–∫–∞ '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö ‚Äî –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª –µ–∂–µ–¥–Ω–µ–≤–Ω—ã—Ö –ø—Ä–æ–¥–∞–∂.")
            return

        if '–¶–µ–Ω–∞' not in df_all.columns:
            logging.error("–ö–æ–ª–æ–Ω–∫–∞ '–¶–µ–Ω–∞' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö ‚Äî –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª —Å —Ü–µ–Ω–∞–º–∏.")
            return

        # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏ —Ü–µ–Ω—ã (—Ü–µ–Ω–∞ ‚Äî –ø–µ—Ä–≤–∞—è –∑–∞ –¥–µ–Ω—å)
        df_daily = (
            df_all
            .sort_values('–î–∞—Ç–∞')  # —á—Ç–æ–±—ã first() —Ä–∞–±–æ—Ç–∞–ª –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
            .groupby(['–î–∞—Ç–∞', '–ê—Ä—Ç–∏–∫—É–ª', '–°–∫–ª–∞–¥'], as_index=False)
            .agg({
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': 'sum',
                '–¶–µ–Ω–∞': 'first'
            })
            .rename(columns={'–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': '–í—Å–µ–≥–æ_–ø—Ä–æ–¥–∞–Ω–æ', '–¶–µ–Ω–∞': '–¶–µ–Ω–∞_–≤_–Ω–∞—á–∞–ª–µ_–¥–Ω—è'})
        )

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞
        df_daily.sort_values(['–î–∞—Ç–∞', '–°–∫–ª–∞–¥', '–ê—Ä—Ç–∏–∫—É–ª'], inplace=True)

        # ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ CSV
        df_daily.to_csv(output_path, index=False, encoding='utf-8-sig')
        logging.info(f"üìÅ CSV-—Ñ–∞–π–ª —Å –¥–Ω–µ–≤–Ω—ã–º–∏ –ø—Ä–æ–¥–∞–∂–∞–º–∏ –∏ —Ü–µ–Ω–∞–º–∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_path}")

    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞ —Å –¥–Ω–µ–≤–Ω—ã–º–∏ –ø—Ä–æ–¥–∞–∂–∞–º–∏: {e}")


@timing_decorator
def analyze_with_restock_vectorized_monthly(df_all):
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞—Ç—É –≤ datetime –∏ –¥–æ–±–∞–≤–∏–º –∫–æ–ª–æ–Ω–∫–∏ –ì–æ–¥ –∏ –ú–µ—Å—è—Ü
    df_all = df_all.sort_values(['–ê—Ä—Ç–∏–∫—É–ª', '–°–∫–ª–∞–¥', '–î–∞—Ç–∞']).copy()
    df_all['–î–∞—Ç–∞'] = pd.to_datetime(df_all['–î–∞—Ç–∞'], format='%d-%m-%Y')
    df_all['–ì–æ–¥'] = df_all['–î–∞—Ç–∞'].dt.year
    df_all['–ú–µ—Å—è—Ü'] = df_all['–î–∞—Ç–∞'].dt.month

    # –†–∞–∑–Ω–∏—Ü–∞ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –¥–ª—è –ø–æ–¥—Å—á—ë—Ç–∞ –ø—Ä–æ–¥–∞–Ω–æ / –ø–æ–ø–æ–ª–Ω–µ–Ω–∏–µ
    df_all['diff_qty'] = df_all.groupby(['–ê—Ä—Ç–∏–∫—É–ª', '–°–∫–ª–∞–¥'])['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'].diff().fillna(0)

    # –ü—Ä–æ–¥–∞–Ω–æ ‚Äî –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞
    df_all['–ü—Ä–æ–¥–∞–Ω–æ'] = (-df_all['diff_qty']).clip(lower=0)
    # –ü–æ–ø–æ–ª–Ω–µ–Ω–∏–µ ‚Äî –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞
    df_all['–ü–æ–ø–æ–ª–Ω–µ–Ω–∏–µ'] = df_all['diff_qty'].clip(lower=0)

    # –ü–æ–∏—Å–∫ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–π ‚Äî –ø–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–º —Å–∫–ª–∞–¥–µ –∏ —É–º–µ–Ω—å—à–µ–Ω–∏–µ –Ω–∞ –¥—Ä—É–≥–æ–º –≤ —Ç–æ—Ç –∂–µ –¥–µ–Ω—å –∏ —Å —Ç–µ–º –∂–µ –∞—Ä—Ç–∏–∫—É–ª–æ–º –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º
    restock_rows = df_all[df_all['diff_qty'] > 0][['–î–∞—Ç–∞', '–ê—Ä—Ç–∏–∫—É–ª', '–°–∫–ª–∞–¥', 'diff_qty']].copy()
    restock_rows.rename(columns={'–°–∫–ª–∞–¥': '–°–∫–ª–∞–¥_–∫—É–¥–∞', 'diff_qty': '–ö–æ–ª-–≤–æ'}, inplace=True)

    sold_rows = df_all[df_all['diff_qty'] < 0][['–î–∞—Ç–∞', '–ê—Ä—Ç–∏–∫—É–ª', '–°–∫–ª–∞–¥', 'diff_qty']].copy()
    sold_rows.rename(columns={'–°–∫–ª–∞–¥': '–°–∫–ª–∞–¥_–æ—Ç–∫—É–¥–∞', 'diff_qty': '–ö–æ–ª-–≤–æ'}, inplace=True)
    sold_rows['–ö–æ–ª-–≤–æ'] = -sold_rows['–ö–æ–ª-–≤–æ']

    merged_moves = pd.merge(
        restock_rows,
        sold_rows,
        on=['–î–∞—Ç–∞', '–ê—Ä—Ç–∏–∫—É–ª', '–ö–æ–ª-–≤–æ'],
        how='inner',
        suffixes=('_–∫—É–¥–∞', '_–æ—Ç–∫—É–¥–∞')
    )
    merged_moves = merged_moves[merged_moves['–°–∫–ª–∞–¥_–∫—É–¥–∞'] != merged_moves['–°–∫–ª–∞–¥_–æ—Ç–∫—É–¥–∞']]

    # –£–±–∏—Ä–∞–µ–º –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è –∏–∑ –ü–æ–ø–æ–ª–Ω–µ–Ω–∏—è –∏ –ü—Ä–æ–¥–∞–Ω–æ
    for idx, row in merged_moves.iterrows():
        mask_restock = (
            (df_all['–î–∞—Ç–∞'] == row['–î–∞—Ç–∞']) &
            (df_all['–ê—Ä—Ç–∏–∫—É–ª'] == row['–ê—Ä—Ç–∏–∫—É–ª']) &
            (df_all['–°–∫–ª–∞–¥'] == row['–°–∫–ª–∞–¥_–∫—É–¥–∞']) &
            (df_all['diff_qty'] == row['–ö–æ–ª-–≤–æ'])
        )
        df_all.loc[mask_restock, '–ü–æ–ø–æ–ª–Ω–µ–Ω–∏–µ'] = 0

        mask_sold = (
            (df_all['–î–∞—Ç–∞'] == row['–î–∞—Ç–∞']) &
            (df_all['–ê—Ä—Ç–∏–∫—É–ª'] == row['–ê—Ä—Ç–∏–∫—É–ª']) &
            (df_all['–°–∫–ª–∞–¥'] == row['–°–∫–ª–∞–¥_–æ—Ç–∫—É–¥–∞']) &
            (df_all['diff_qty'] == -row['–ö–æ–ª-–≤–æ'])
        )
        df_all.loc[mask_sold, '–ü—Ä–æ–¥–∞–Ω–æ'] = 0

    –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è = merged_moves.rename(columns={
        '–î–∞—Ç–∞': '–î–∞—Ç–∞',
        '–ê—Ä—Ç–∏–∫—É–ª': '–ê—Ä—Ç–∏–∫—É–ª',
        '–°–∫–ª–∞–¥_–æ—Ç–∫—É–¥–∞': '–°–∫–ª–∞–¥_–æ—Ç–∫—É–¥–∞',
        '–°–∫–ª–∞–¥_–∫—É–¥–∞': '–°–∫–ª–∞–¥_–∫—É–¥–∞',
        '–ö–æ–ª-–≤–æ': '–ö–æ–ª-–≤–æ'
    })[['–î–∞—Ç–∞', '–ê—Ä—Ç–∏–∫—É–ª', '–°–∫–ª–∞–¥_–æ—Ç–∫—É–¥–∞', '–°–∫–ª–∞–¥_–∫—É–¥–∞', '–ö–æ–ª-–≤–æ']].to_dict(orient='records')

    # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –≥–æ–¥—É, –º–µ—Å—è—Ü—É, —Å–∫–ª–∞–¥—É –∏ –∞—Ä—Ç–∏–∫—É–ª—É
    df_sales = df_all.groupby(['–ê—Ä—Ç–∏–∫—É–ª', '–°–∫–ª–∞–¥', '–ì–æ–¥', '–ú–µ—Å—è—Ü']).agg(
        –ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞=('–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞', 'first'),
        –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å=('–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å', 'first'),
        –í—Å–µ–≥–æ_–ø—Ä–æ–¥–∞–Ω–æ=('–ü—Ä–æ–¥–∞–Ω–æ', 'sum'),
        –í—Å–µ–≥–æ_–ø–æ–ø–æ–ª–Ω–µ–Ω–æ=('–ü–æ–ø–æ–ª–Ω–µ–Ω–∏–µ', 'sum'),
        –î–Ω–µ–π_–ø—Ä–æ–¥–∞–∂=('–ü—Ä–æ–¥–∞–Ω–æ', lambda x: (x > 0).sum()),
        –°—Ä–µ–¥–Ω—è—è_—Ü–µ–Ω–∞=('–¶–µ–Ω–∞', 'mean'),
        –ú–∏–Ω_—Ü–µ–Ω–∞=('–¶–µ–Ω–∞', 'min'),
        –ú–∞–∫—Å_—Ü–µ–Ω–∞=('–¶–µ–Ω–∞', 'max'),
        –î–Ω–µ–π_–≤_–Ω–∞–ª–∏—á–∏–∏=('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', lambda x: (x > 0).sum()),
        –ü–æ—Å–ª–µ–¥–Ω–∏–π_–æ—Å—Ç–∞—Ç–æ–∫=('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', 'last'),
        –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö_–¥–Ω–µ–π=('–î–∞—Ç–∞', 'nunique')
    ).reset_index()

    # –ö–æ—Ä—Ä–µ–∫—Ü–∏—è: –¥–Ω–µ–π –≤ –Ω–∞–ª–∏—á–∏–∏ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –±–æ–ª—å—à–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–Ω–µ–π
    df_sales['–î–Ω–µ–π_–≤_–Ω–∞–ª–∏—á–∏–∏'] = df_sales[['–î–Ω–µ–π_–≤_–Ω–∞–ª–∏—á–∏–∏', '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö_–¥–Ω–µ–π']].min(axis=1)

    # –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç—å –ø–æ –º–µ—Å—è—Ü—É (—á—Ç–æ–±—ã –Ω–µ –¥–µ–ª–∏—Ç—å –Ω–∞ 0, –∑–∞–º–µ–Ω—è–µ–º 0 –Ω–∞ 1)
    df_sales['–û–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç—å'] = df_sales['–í—Å–µ–≥–æ_–ø—Ä–æ–¥–∞–Ω–æ'] / df_sales['–î–Ω–µ–π_–ø—Ä–æ–¥–∞–∂'].replace(0, 1)

    # –¶–µ–Ω—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ –º–µ—Å—è—Ü–∞
    df_price = df_all.sort_values('–î–∞—Ç–∞').groupby(['–ê—Ä—Ç–∏–∫—É–ª', '–°–∫–ª–∞–¥', '–ì–æ–¥', '–ú–µ—Å—è—Ü']).agg(
        –¶–µ–Ω–∞_–≤_–Ω–∞—á–∞–ª–µ=('–¶–µ–Ω–∞', 'first'),
        –¶–µ–Ω–∞_–≤_–∫–æ–Ω—Ü–µ=('–¶–µ–Ω–∞', 'last')
    ).reset_index()

    # –ü–æ–¥—Å—á—ë—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π —Ü–µ–Ω—ã –ø–æ –¥–Ω—è–º –≤–Ω—É—Ç—Ä–∏ –º–µ—Å—è—Ü–∞
    def count_price_changes_daily(group):
        daily_prices = group.groupby(group['–î–∞—Ç–∞'].dt.date)['–¶–µ–Ω–∞'].first()
        # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–º–µ–Ω —Ü–µ–Ω—ã (—Å—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–ª–∏—á–∏–π –º–µ–∂–¥—É —Å–æ—Å–µ–¥–Ω–∏–º–∏ –¥–Ω—è–º–∏)
        return daily_prices.ne(daily_prices.shift()).sum() - 1  # -1, —á—Ç–æ–±—ã –Ω–µ —Å—á–∏—Ç–∞—Ç—å –ø–µ—Ä–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∫–∞–∫ –∏–∑–º–µ–Ω–µ–Ω–∏–µ

    price_changes = (
        df_all.groupby(['–ê—Ä—Ç–∏–∫—É–ª', '–°–∫–ª–∞–¥', '–ì–æ–¥', '–ú–µ—Å—è—Ü'], group_keys=False)
        .apply(lambda g: pd.Series({'–ö–æ–ª_–≤–æ_–∏–∑–º–µ–Ω–µ–Ω–∏–π_—Ü–µ–Ω—ã': count_price_changes_daily(g)}))
        .reset_index()
    )

    # –ò—Ç–æ–≥–æ–≤–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
    df_result = pd.merge(df_sales, df_price, on=['–ê—Ä—Ç–∏–∫—É–ª', '–°–∫–ª–∞–¥', '–ì–æ–¥', '–ú–µ—Å—è—Ü'], how='left')
    df_result = pd.merge(df_result, price_changes, on=['–ê—Ä—Ç–∏–∫—É–ª', '–°–∫–ª–∞–¥', '–ì–æ–¥', '–ú–µ—Å—è—Ü'], how='left')

    df_result['–ö–æ–ª_–≤–æ_–∏–∑–º–µ–Ω–µ–Ω–∏–π_—Ü–µ–Ω—ã'] = df_result['–ö–æ–ª_–≤–æ_–∏–∑–º–µ–Ω–µ–Ω–∏–π_—Ü–µ–Ω—ã'].fillna(0).astype(int)
    df_result['–ò–∑–º–µ–Ω–µ–Ω–∏–µ_—Ü–µ–Ω—ã'] = df_result['–¶–µ–Ω–∞_–≤_–∫–æ–Ω—Ü–µ'] - df_result['–¶–µ–Ω–∞_–≤_–Ω–∞—á–∞–ª–µ']
    df_result['–ò–∑–º–µ–Ω–µ–Ω–∏–µ_—Ü–µ–Ω—ã_%'] = df_result.apply(
        lambda row: ((row['–ò–∑–º–µ–Ω–µ–Ω–∏–µ_—Ü–µ–Ω—ã'] / row['–¶–µ–Ω–∞_–≤_–Ω–∞—á–∞–ª–µ']) * 100) if row['–¶–µ–Ω–∞_–≤_–Ω–∞—á–∞–ª–µ'] else 0,
        axis=1
    ).round(2)

    return df_result, –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è
@timing_decorator
def detect_sales_peaks(df_all: pd.DataFrame,
                       output_path: str = '–≤—Å–ø–ª–µ—Å–∫–∏_–ø—Ä–æ–¥–∞–∂.xlsx',
                       multiplier: float = 2.0,
                       min_days_for_stats: int = 3) -> pd.DataFrame:
    """
    –ù–∞—Ö–æ–¥–∏—Ç –≤—Å–ø–ª–µ—Å–∫–∏: –¥–Ω–∏, –∫–æ–≥–¥–∞ –í—Å–µ–≥–æ_–ø—Ä–æ–¥–∞–Ω–æ > –°—Ä–µ–¥–Ω–µ–µ + multiplier * –°—Ç–¥–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ
    –î–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏:
      - –°—Ç–¥–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –¥–ª—è –≥—Ä—É–ø–ø —Å < min_days_for_stats –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è (–ø–∏–∫ –Ω–µ —Å—á–∏—Ç–∞–µ—Ç—Å—è).
      - –ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞ –ø–æ–¥—Ç—è–≥–∏–≤–∞–µ—Ç—Å—è –∫–∞–∫ –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–∞—è –¥–ª—è –ø–∞—Ä—ã (–ê—Ä—Ç–∏–∫—É–ª, –°–∫–ª–∞–¥).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç DataFrame –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –≤—Å–ø–ª–µ—Å–∫–æ–≤ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ Excel.
    """
    try:
        logging.info("üìà –ü–æ–∏—Å–∫ –≤—Å–ø–ª–µ—Å–∫–æ–≤ –ø—Ä–æ–¥–∞–∂...")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        required_cols = ['–î–∞—Ç–∞', '–ê—Ä—Ç–∏–∫—É–ª', '–°–∫–ª–∞–¥', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ']
        if not all(col in df_all.columns for col in required_cols):
            logging.error(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {required_cols}")
            return pd.DataFrame()

        df = df_all.copy()

        # –ü—Ä–∏–≤–æ–¥–∏–º —Ç–∏–ø—ã –∏ –æ—á–∏—â–∞–µ–º
        df['–î–∞—Ç–∞'] = pd.to_datetime(df['–î–∞—Ç–∞'], errors='coerce')
        df['–ê—Ä—Ç–∏–∫—É–ª'] = df['–ê—Ä—Ç–∏–∫—É–ª'].astype(str).str.strip()
        df['–°–∫–ª–∞–¥'] = df['–°–∫–ª–∞–¥'].astype(str).str.strip()
        df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'] = pd.to_numeric(df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'], errors='coerce').fillna(0)

        df = df.dropna(subset=['–î–∞—Ç–∞', '–ê—Ä—Ç–∏–∫—É–ª', '–°–∫–ª–∞–¥'])
        if df.empty:
            logging.warning("–î–∞–Ω–Ω—ã–µ –ø—É—Å—Ç—ã –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ (–Ω–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –î–∞—Ç–∞/–ê—Ä—Ç–∏–∫—É–ª/–°–∫–ª–∞–¥).")
            return pd.DataFrame()

        # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø—Ä–æ–¥–∞–∂–∏ –ø–æ –¥–∞—Ç–µ, –∞—Ä—Ç–∏–∫—É–ª—É, —Å–∫–ª–∞–¥—É
        df_daily = (
            df.groupby(['–î–∞—Ç–∞', '–ê—Ä—Ç–∏–∫—É–ª', '–°–∫–ª–∞–¥'], as_index=False)['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ']
              .sum()
              .rename(columns={'–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': '–í—Å–µ–≥–æ_–ø—Ä–æ–¥–∞–Ω–æ'})
        )

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–∞—Ä–µ (–ê—Ä—Ç–∏–∫—É–ª, –°–∫–ª–∞–¥): mean, std, count
        stats = (
            df_daily.groupby(['–ê—Ä—Ç–∏–∫—É–ª', '–°–∫–ª–∞–¥'], as_index=False)['–í—Å–µ–≥–æ_–ø—Ä–æ–¥–∞–Ω–æ']
                    .agg(–°—Ä–µ–¥–Ω–µ–µ='mean', –°—Ç–¥–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ='std', Count='count')
        )
        # –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –≤ std –Ω—É–ª—è–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ)
        stats['–°—Ç–¥–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ'] = stats['–°—Ç–¥–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ'].fillna(0)

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º stats —Å –¥–Ω–µ–≤–Ω—ã–º–∏ –ø—Ä–æ–¥–∞–∂–∞–º–∏
        df_peaks = df_daily.merge(stats, on=['–ê—Ä—Ç–∏–∫—É–ª', '–°–∫–ª–∞–¥'], how='left')

        # –ü–æ—Ä–æ–≥: –µ—Å–ª–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π ‚Äî —Å—Ç–∞–≤–∏–º –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π –ø–æ—Ä–æ–≥ (—á—Ç–æ–±—ã –Ω–µ —Å—á–∏—Ç–∞—Ç—å –ø–∏–∫)
        df_peaks['threshold'] = df_peaks.apply(
            lambda r: (r['–°—Ä–µ–¥–Ω–µ–µ'] + multiplier * r['–°—Ç–¥–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ'])
                      if r['Count'] >= min_days_for_stats else np.inf,
            axis=1
        )

        df_peaks['–í—Å–ø–ª–µ—Å–∫'] = df_peaks['–í—Å–µ–≥–æ_–ø—Ä–æ–¥–∞–Ω–æ'] > df_peaks['threshold']

        df_peaks_only = df_peaks[df_peaks['–í—Å–ø–ª–µ—Å–∫']].copy()
        if df_peaks_only.empty:
            logging.info("–í—Å–ø–ª–µ—Å–∫–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª (–ø–æ –∂–µ–ª–∞–Ω–∏—é) –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π DF
            pd.DataFrame().to_excel(output_path, index=False)
            return df_peaks_only

        # –í—ã–±–∏—Ä–∞–µ–º –Ω–∞–¥—ë–∂–Ω—É—é –ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—É: –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–∞—è –¥–ª—è –ø–∞—Ä—ã (–ê—Ä—Ç–∏–∫—É–ª, –°–∫–ª–∞–¥)
        def most_common_nom(series):
            vals = series.dropna().astype(str)
            if vals.empty:
                return np.nan
            return vals.value_counts().index[0]

        sku_nom = (
            df.groupby(['–ê—Ä—Ç–∏–∫—É–ª', '–°–∫–ª–∞–¥'], as_index=False)['–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞']
              .agg(most_common_nom)
              .rename(columns={'–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞': '–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞_–≤—ã–±—Ä–∞–Ω–Ω–∞—è'})
        )

        # –ú–µ—Ä–∂–∏–º –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—É—é –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—É ‚Äî –Ω–µ –±—É–¥–µ—Ç –º–Ω–æ–∂–∏—Ç—å —Å—Ç—Ä–æ–∫–∏
        df_peaks_only = df_peaks_only.merge(sku_nom, on=['–ê—Ä—Ç–∏–∫—É–ª', '–°–∫–ª–∞–¥'], how='left')

        # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –∫–ª—é—á–∞–º (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
        df_peaks_only = df_peaks_only.drop_duplicates(subset=['–î–∞—Ç–∞', '–ê—Ä—Ç–∏–∫—É–ª', '–°–∫–ª–∞–¥'])

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞—Ç—É –¥–ª—è Excel
        df_peaks_only['–î–∞—Ç–∞'] = df_peaks_only['–î–∞—Ç–∞'].dt.strftime('%d/%m/%Y')

        # –ü–µ—Ä–µ–∏–º–µ–Ω—É–µ–º –∫–æ–ª–æ–Ω–∫—É —Å –≤—ã–±—Ä–∞–Ω–Ω–æ–π –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–æ–π –≤ –ø—Ä–∏–≤—ã—á–Ω–æ–µ –∏–º—è
        df_peaks_only = df_peaks_only.rename(columns={'–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞_–≤—ã–±—Ä–∞–Ω–Ω–∞—è': '–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞'})

        # –£–ø–æ—Ä—è–¥–æ—á–∏–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
        cols_order = ['–î–∞—Ç–∞', '–ê—Ä—Ç–∏–∫—É–ª', '–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞', '–°–∫–ª–∞–¥', '–í—Å–µ–≥–æ_–ø—Ä–æ–¥–∞–Ω–æ', '–°—Ä–µ–¥–Ω–µ–µ', '–°—Ç–¥–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ', 'Count', 'threshold', '–í—Å–ø–ª–µ—Å–∫']
        cols = [c for c in cols_order if c in df_peaks_only.columns] + [c for c in df_peaks_only.columns if c not in cols_order]
        df_peaks_only = df_peaks_only[cols]

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        df_peaks_only.to_excel(output_path, index=False)
        logging.info(f"‚úÖ –§–∞–π–ª —Å–æ –≤—Å–ø–ª–µ—Å–∫–∞–º–∏ –ø—Ä–æ–¥–∞–∂ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path} (—Å—Ç—Ä–æ–∫: {len(df_peaks_only)})")

        return df_peaks_only

    except Exception as e:
        logging.exception(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –≤—Å–ø–ª–µ—Å–∫–æ–≤ –ø—Ä–æ–¥–∞–∂: {e}")
        return pd.DataFrame()

@timing_decorator
def run_month_analysis():
    logging.info("üîç –ù–∞—á–∞–ª–æ –∞–Ω–∞–ª–∏–∑–∞ –º–µ—Å—è—Ü–∞")

    df_moscow = process_folder('data/moscow', '–ú–æ—Å–∫–≤–∞')
    df_khabarovsk = process_folder('data/khabarovsk', '–•–∞–±–∞—Ä–æ–≤—Å–∫')

    if df_moscow is None and df_khabarovsk is None:
        logging.error("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return

    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ –±–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞
    df_all = pd.concat([df for df in [df_moscow, df_khabarovsk] if df is not None], ignore_index=True)
    df_all.dropna(subset=['–ê—Ä—Ç–∏–∫—É–ª'], inplace=True)
    df_all['–ê—Ä—Ç–∏–∫—É–ª'] = df_all['–ê—Ä—Ç–∏–∫—É–ª'].astype(str).str.strip()

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç—ã
    if '–î–∞—Ç–∞' in df_all.columns:
        df_all['–î–∞—Ç–∞'] = pd.to_datetime(df_all['–î–∞—Ç–∞'], errors='coerce')

    # –û—Å–Ω–æ–≤–Ω–æ–π –∞–Ω–∞–ª–∏–∑
    df_result, df_flags = analyze_with_restock_vectorized_monthly(df_all)
    if df_result is None:
        logging.error("‚ùå –ê–Ω–∞–ª–∏–∑ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω ‚Äî df_result –ø—É—Å—Ç")
        return

    if isinstance(df_flags, list):
        if len(df_flags) > 0:
            df_flags = pd.DataFrame(df_flags)
        else:
            df_flags = pd.DataFrame()

    if not df_flags.empty and '–î–∞—Ç–∞' in df_flags.columns:
        df_flags['–î–∞—Ç–∞'] = pd.to_datetime(df_flags['–î–∞—Ç–∞'], errors='coerce').dt.strftime('%d/%m/%Y')

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Ç–æ–≥–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤
    df_result.to_excel('–∏—Ç–æ–≥_–ø–æ_–º–µ—Å—è—Ü—É.xlsx', index=False)
    df_flags.to_excel('—Ñ–∏–∫—Å–∞—Ü–∏—è_–ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–π.xlsx', index=False)

    # –¢–æ–ø—ã
    top_fast = df_result[df_result['–í—Å–µ–≥–æ_–ø—Ä–æ–¥–∞–Ω–æ'] > 0].sort_values('–û–±–æ—Ä–∞—á–∏–≤–∞–µ–º–æ—Å—Ç—å', ascending=False).head(1000)
    top_slow = df_result[df_result['–í—Å–µ–≥–æ_–ø—Ä–æ–¥–∞–Ω–æ'] == 0].sort_values('–î–Ω–µ–π_–≤_–Ω–∞–ª–∏—á–∏–∏', ascending=False).head(1000)
    top_restocked = df_result.sort_values('–í—Å–µ–≥–æ_–ø–æ–ø–æ–ª–Ω–µ–Ω–æ', ascending=False).head(1000)

    top_fast.to_excel('—Å–∞–º—ã–µ_—Ö–æ–¥–æ–≤—ã–µ.xlsx', index=False)
    top_slow.to_excel('–∑–∞–ª–µ–∂–∞–ª—ã–µ.xlsx', index=False)
    top_restocked.to_excel('—á–∞—â–µ_–≤—Å–µ–≥–æ_–ø–æ–ø–æ–ª–Ω—è–ª–∏—Å—å.xlsx', index=False)


    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –µ–∂–µ–¥–Ω–µ–≤–Ω—ã—Ö –ø—Ä–æ–¥–∞–∂
    generate_daily_sales_file(df_all, output_path='–∏—Ç–æ–≥_–¥–Ω–µ–≤–Ω—ã–µ_–ø—Ä–æ–¥–∞–∂–∏.csv')

    # –í—Å–ø–ª–µ—Å–∫–∏ –ø—Ä–æ–¥–∞–∂
    detect_sales_peaks(df_all, output_path='–≤—Å–ø–ª–µ—Å–∫–∏_–ø—Ä–æ–¥–∞–∂.xlsx')

    logging.info("‚úÖ –ê–Ω–∞–ª–∏–∑ –º–µ—Å—è—Ü–∞ –∑–∞–≤–µ—Ä—à–µ–Ω")


if __name__ == '__main__':
    run_month_analysis()